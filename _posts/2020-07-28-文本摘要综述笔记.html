<html>
<head>
  <title>Evernote Export</title>
  <basefont face="微软雅黑" size="2" />
  <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
  <meta name="exporter-version" content="YXBJ Windows/601935 (zh-CN, DDL); Windows/10.0.0 (Win64); EDAMVersion=V2;"/>
  <style>
    body, td {
      font-family: 微软雅黑;
      font-size: 10pt;
    }
  </style>
</head>
<body>
<a name="2066"/>
<h1>摘要笔记</h1>
<div>
<table bgcolor="#D4DDE5" border="0">
<tr><td><b>创建时间：</b></td><td><i>2020/7/27 15:04</i></td></tr>
<tr><td><b>更新时间：</b></td><td><i>2020/7/27 21:13</i></td></tr>
<tr><td><b>作者：</b></td><td><i>1452538551@qq.com</i></td></tr>
<tr><td><b>标签：</b></td><td><i>摘要</i></td></tr>
<tr><td><b>来源：</b></td><td><a href="https://cloud.tencent.com/developer/article/1539483"><i>https://cloud.tencent.com/developer/article/1539483</i></a></td></tr>
</table>
</div>
<br/>

<div>
<span><div><div><span style="font-weight: bold;">文本摘要简述</span></div><div><br/></div><div><span style="font-weight: bold;">1. 简介</span></div><div>   文本摘要旨在将文本或文本集合转换为包含关键信息的简短摘要。文本摘要按照输入类型可分为<span style="font-weight: bold;">单文档摘要</span>和<span style="font-weight: bold;">多文档摘要</span>。单文档摘要从给定的一个文档中生成摘要，多文档摘要从给定的一组主题相关的文档中生成摘要。按照输出类型可分为<span style="font-weight: bold;">抽取式摘要</span>和<span style="font-weight: bold;">生成式摘要</span>。抽取式摘要从源文档中抽取关键句和关键词组成摘要，摘要全部来源于原文。生成式摘要根据原文，允许生成新的词语、短语来组成摘要。按照有无监督数据可以分为<span style="font-weight: bold;">有监督摘要</span>和<span style="font-weight: bold;">无监督摘要</span>。本文主要关注单文档摘要。</div><div><span style="font-weight: bold;">2. 文本摘要目前实现手段</span></div><div><span style="font-weight: bold;">2.1 抽取式摘要</span></div><div>   抽取式方法从原文中选取关键词、关键句组成摘要。这种方法天然的在语法、句法上错误率低，保证了一定的效果。无监督摘要主要分为图方法、聚类等方式。有监督往往基于神经网络将抽取摘要问题建模为序列标注和句子排序两类任务。</div><div>   抽取式摘要通过选取关键句，最后的性能结果不会受限于句子的通顺性，但是简洁性和可归纳性会相应的受到制约。</div><div>   抽取式摘要通过选取关键词，最后的性能结果会受限于语句的通顺程度。</div><div><span style="font-weight: bold;">2.1.1 无监督抽取式摘要</span></div><div><span style="font-weight: bold;">2.1.1.1</span> <span style="font-weight: bold;">Lead-3</span></div><div>   一般来说，作者常常会在标题和文章开始就表明主题，因此最简单的方法就是抽取文章中的前几句作为摘要。常用的方法为 Lead-3，即抽取文章的前三句作为文章的摘要。Lead-3 方法虽然简单直接，但却是非常有效的方法。</div><ul><li><div>点评：句子通顺性不是问题，但是正确性和归纳性不是很好。</div></li></ul><div><span style="font-weight: bold;">2.1.1.2</span> <span style="font-weight: bold;">TextRank</span></div><div>   TextRank 算法仿照 PageRank，将句子作为节点，使用句子间相似度，构造无向有权边。使用边上的权值迭代更新节点值，最后选取 N 个得分最高的节点，作为摘要。</div><ul><li><div>点评：句子通顺性不是问题，但是归纳性和简洁性不是很好，且相似的句子会重复出现。遗漏一些带有其他主题信息却“势单力薄“的句子</div></li><li><div>改进：</div></li><div>   MMR，全称为Maximal Marginal Relevance。它的核心思想同时考虑了内容相关性和多样性。公式如下：</div><div><img src="摘要笔记_files/640" type="image/png" data-filename="640"/></div><div>   其中，R是原文句子集合，S是当前已有的摘要集合。Q是原文所有句子集合。 <img src="摘要笔记_files/640 [1]" type="image/png" data-filename="640"/> 表示从剩余的文章中选择一个候选摘要句计算MMR。等式右边的第一部分衡量候选句子和原文的相似度。第二部分衡量候选句子和当前已有的摘要集合的冗余性。优化该函数使用的是贪心方法，在每一轮选择摘要句时，计算每个句子的MMR得分，然后选择分数最高的那个放到候选摘要集合中。我们可以将MMR方法与TextRank方法结合起来，各取其优点。别人是这么做的：将等式第一部分，用TextRank学习到的句子的权重得分替换 <img src="摘要笔记_files/640 [2]" type="image/png" data-filename="640"/> 。TextRank的权重得分是在句子相似度的基础上通过无监督学习得到，比直接使用相似度要更全面。</div></ul><div><br/></div><div><span style="font-weight: bold;">2.1.1.3</span> <span style="font-weight: bold;">聚类</span></div><div>   将文章中的句子视为一个点，按照聚类的方式完成摘要。例如 Padmakumar and Saran [1] 将文章中的句子使用 Skip thought vectors 和 Paragram embeddings 两种方式（或者目前各种大热的句子embedding编码方式）进行编码，得到句子级别的向量表示，再使用 K 均值聚类和 Mean-Shift 聚类进行句子聚类，得到 N 个类别。最后从每个类别中，选择距离质心最近的句子，得到 N 个句子，作为最终摘要。</div><ul><li><div>点评：句子通顺性不是问题，但是类别数和质心初始值对结果影响很大。</div></li></ul><div><span style="font-weight: bold;">2.1.2 有监督抽取式摘要</span></div><div>   抽取式摘要可以建模为<span style="font-weight: bold;">序列标注任务</span>进行处理，其核心想法是：为原文中的每一个句子打一个二分类标签（0 或 1），0 代表该句不属于摘要，1 代表该句属于摘要。最终摘要由所有标签为 1 的句子构成。</div><div>   或者<span style="font-weight: bold;">句子打分机制</span></div><div><span style="font-weight: bold;">2.1.2.1</span> <span style="font-weight: bold;">序列标注摘要基本框架</span></div><div>   将文本摘要建模为序列标注任务的关键在于获得句子的表示，即将句子编码为一个向量，根据该向量进行二分类任务，例如 AAAI17 中，Nallapati 等人[2]的工作，使用双向 GRU 分别建模词语级别和句子级别的表示。其模型 SummaRuNNer 如图 1所示。蓝色部分为词语级别表示，红色部分为句子级别表示，对于每一个句子表示，有一个 0、1 标签输出，指示其是否是摘要。</div><div style="text-align: center;"><img src="摘要笔记_files/640 [3]" type="image/jpeg" data-filename="640"/></div><div style="text-align: center;"> 图1 SummaRuNNer 模型</div><div>   该模型的训练需要监督数据，现有数据集往往没有对应的句子级别的标签，因此需要通过启发式规则进行获取。具体方法为：首先选取原文中与标准摘要计算 ROUGE 得分最高的一句话加入候选集合，接着继续从原文中进行选择，保证选出的摘要集合 ROUGE 得分增加，直至无法满足该条件。得到的候选摘要集合对应的句子设为 1 标签，其余为 0 标签。</div><ul><li><div>相似模型：</div></li><ul><li><div><h1><span style="font-size: 10pt;">NN-SE</span></h1></div></li><li><div><span style="font-weight: bold;">Document Reader</span></div></li></ul><div style="text-align: center;">   <img src="摘要笔记_files/Image.png" type="image/png" data-filename="Image.png" width="338"/></div></ul><div><span style="font-weight: bold;">2.1.2.2</span> <span style="font-weight: bold;">序列标注结合Seq2Seq</span></div><div>   抽取式摘要还可以在序列标注的基础上结合 Seq2Seq 和强化学习完成。ACL18 中，Zhang等人[3]在序列标注的基础上，使用 Seq2Seq 学习一个句子压缩模型，使用该模型来衡量选择句子的好坏，并结合强化学习完成模型训练。其模型 Latent 如图 2所示。</div><div>   该方法的核心关注点是：摘要数据集往往没有对应的句子级别的标签，需要通过启发式规则获取，然而仅仅利用这些标签训练模型会丢失很多标准摘要中重要的信息。因此 Latent 模型不采用序列标注方法计算标签级别的损失来训练模型，而是将序列标注作为中间的步骤。在得到序列标注的概率分布之后，从中采样候选摘要集合，与标准摘要对比计算损失，可以更好地利用标准摘要中的信息。</div><div style="text-align: center;"><img src="摘要笔记_files/640 [4]" type="image/jpeg" data-filename="640"/></div><div style="text-align: center;">图2 Latent 模型</div><ul><li><div>相似模型：</div></li><ul><li><div><h3><span style="font-weight: bold;">Sentence Extractor</span></h3></div></li></ul><div style="text-align: center;"><span style="font-weight: bold;"><img src="摘要笔记_files/Image [1].png" type="image/png" data-filename="Image.png"/></span></div><div><span style="font-weight: bold;"> </span>  其中MLP是一个多层神经网络，输入为hˉt 和ht 的拼接，pt−1 表示extractor多大程度上认为前一个句子应该被抽取。在实践中，模型的训练和测试存在一个矛盾：在训练阶段，我们知道前一个句子的真实标签pt−1 ，然而在测试阶段，pt−1 是未知的，需要预测的。这个矛盾会造成预测误差的快速积累，特别是当错误发生在标注的早期。为了解决这个问题，作者采用了curriculum learning strategy：在训练的开始时，当pt−1 没有正确预测，就将其改为正确的标签。</div></ul><div style="background-color: rgb(255, 255, 255); padding: 0px; margin: 0.8em 0px; clear: both; min-height: 1em; max-width: 100%; box-sizing: border-box; overflow-wrap: break-word; orphans: 4; white-space: pre-wrap; caret-color: rgb(51, 51, 51); font-size: 16px; text-align: justify; text-size-adjust: auto;"></div><h4><span style="font-weight: bold;">2.1.2.3</span> <span style="font-weight: bold;">句子排序方式</span></h4><div>   抽取式摘要还可以建模为句子排序任务完成，与序列标注任务的不同点在于，序列标注对于每一个句子表示打一个 0、1 标签，而句子排序任务则是针对每个句子输出其是否是摘要句的概率，最终依据概率，选取 top k 个句子作为最终摘要。虽然任务建模方式（最终选取摘要方式）不同，但是其核心关注点都是对于句子表示的建模。</div><div>   之前的抽取式摘要往往建模句子级别的表示，忽略了关键词的作用。ACL18 中，Jadhav and Rajan等人[4]直接使用 Seq2Seq 模型来交替生成词语和句子的索引序列来完成抽取式摘要任务。其模型 SWAP-NET 在解码的每一步，计算一个 Switch 概率指示生成词语或者句子。最后解码出的是词语和句子的混合序列。最终摘要由产生的句子集合选出。除了考虑生成句子本身的概率之外，还需要考虑该句是否包含了生成的词语，如果包含，则得分高，最终选择 top k 句作为摘要。</div><div style="text-align: center;"><img src="摘要笔记_files/Image [2].png" type="image/png" data-filename="Image.png" style="font-size: 12pt;" width="468"/></div><div><br/></div><ul><li><div><h5>改进：</h5></div></li><div>   之前的模型都是在得到句子的表示以后对于句子进行打分，这就造成了打分与选择是分离的，先打分，后根据得分进行选择。没有利用到句子之间的关系。在 ACL18 中，Zhou 等人[15]提出了一种新的打分方式，使用句子受益作为打分方式，考虑到了句子之间的相互关系。其模型 <span style="font-weight: bold;">NeuSUM</span> 如图 3所示。</div><div>   句子编码部分与之前基本相同。打分和抽取部分使用单向 GRU 和双层 MLP 完成。单向 GRU 用于记录过去抽取句子的情况，双层 MLP 用于打分。打分如下公式所示。</div><div style="text-align: center;"><img src="摘要笔记_files/640 [5]" type="image/png" data-filename="640"/></div><div>   其中 r 代表 ROUGE 评价指标，<img src="摘要笔记_files/640 [6]" type="image/png" data-filename="640"/>代表已经选择的句子集合，<img src="摘要笔记_files/640 [7]" type="image/png" data-filename="640"/>代表候选句子，目标是使 得 g 越大越好，即选择最大化收益的句子。</div></ul><div style="text-align: center;"><img src="摘要笔记_files/640 [8]" type="image/jpeg" data-filename="640"/></div><div style="text-align: center;">图3 NeuSUM 模型</div><div>   因此在打分和选择部分，逐步选择使得 g 最高的句子，直到无法满足该条件或者达到停止条件为止。集合 S 为最终摘要。</div><div>   看不懂的话可参考这篇文章：</div><div><a href="https://blog.csdn.net/hohaizx/article/details/83506270">   https://blog.csdn.net/hohaizx/article/details/83506270</a></div><div><b><br/></b></div><div><b>2.2 生成式摘要</b></div><div>   抽取式摘要在语法、句法上有一定的保证，但是也面临了一定的问题，例如：内容选择错误、连贯性差、灵活性差等问题。生成式摘要允许摘要中包含新的词语或短语，灵活性高，随着近几年神经网络模型的发展，序列到序列（Seq2Seq）模型被广泛的用于生成式摘要任务，并取得一定的成果。</div><div>   仅使用 Seq2Seq 来完成生成式摘要存在如下问题：（1）未登录词问题（OOV），（2）生成重复。现在被广泛应用于生成式摘要的框架由 See 等人[13]在 ACL17 中提出，在基于注意力机制的 Seq2Seq 基础上增加了 Copy 和 Coverage 机制，有效的缓解了上述问题。其模型 pointer-generator 网络如图 4所示。</div><div style="text-align: center;"><img src="摘要笔记_files/640 [9]" type="image/jpeg" data-filename="640"/></div><div style="text-align: center;">图4 Pointer-Generator 模型</div><div>   其模型基本部分为基于注意力机制的 Seq2Seq 模型，使用每一步解码的隐层状态与编码器的隐层状态计算权重，最终得到 context 向量，利用 context 向量和解码器隐层状态计算输出概率。</div><div>利用 Copy 机制，需要在解码的每一步计算拷贝或生成的概率，因为词表是固定的，该机制可以选择从原文中拷贝词语到摘要中，有效的缓解了未登录词（OOV）的问题。</div><div>利用 Coverage 机制，需要在解码的每一步考虑之前步的 attention 权重，结合 coverage 损失， 避免继续考虑已经获得高权重的部分。该机制可以有效缓解生成重复的问题。</div><div>基于该框架可以做出一些改进，在 ICLR18 中，Paulus 等人[5]，在该框架的基础上又使用解码器注意力机制结合强化学习来完成生成式摘要。</div><div>基于上述 Coverage 机制，在 EMNLP18 中，Li 等人[6]基于句子级别的注意力机制，使用句子级别的 Coverage 来使得不同的摘要句可以关注不同的原文，缓解了生成信息重复的问题。</div><div><b><br/></b></div><div><b>2.2.1 利用外部信息</b><span style="font-weight: bold;">（可以借鉴，在生成新的精简描述时，可以利用已有的引导语之间的相似度，计算候选精简描述）</span></div><div>   除上述问题以外，基于 Seq2Seq 的模型往往对长文本生成不友好，对于摘要来说，更像是一种句子压缩，而不是一种摘要。因此在 ACL18 中，Cao 等人[7]，使用真实摘要来指导文本摘要的生成。其核心想法在于：相似句子的摘要也具有一定相似度，将这些摘要作为软模板，作为外部知识进行辅助。其模型<img src="摘要笔记_files/640 [10]" type="image/png" data-filename="640"/> Sum 一共包含 Retrieve、Rerank、Rewrite 三个部分。</div><div>Retrieve 部分主要检索相似句子，获得候选摘要。Rerank 部分用于排序候选模板，在训练集中，计算候选与真实摘要的 ROUGE 得分作为排序依据，在开发集与测试集中，使用神经网络计算得分作为排序依据。训练过程中，使得预测得分尽可能与真实得分一致。Rewrite 部分，结合候选模板与原文生成摘要。</div><h4><span style="font-weight: bold;">2.2.2 多任务学习（可以用于帮助训练模型，比如现在的引导语对，精简描述和引导语对，精简描述和思路文本对，引导语和思路文本对）</span></h4><div>   除了将本身数据集的信息作为一种外部知识以外，在 ACL18 中，Guo 等人[8]将摘要生成作为主任务，问题生成、蕴含生成作为辅助任务进行多任务学习。问题生成任务需要根据给定的文本和答案生成问题，要求模型具有选择重要信息的能力，蕴含生成任务要求根据给定文本，有逻辑地推出输出文本，要求模型具有逻辑推理能力。在文本摘要中，定位原文中的关键信息是核心问题，根据原文生成摘要又要求模型具有一定的逻辑推理能力，使得生成的摘要与原文不违背，无矛盾</div><div style="background-color: rgb(255, 255, 255); padding: 0px; margin: 0.8em 0px; clear: both; min-height: 1em; max-width: 100%; box-sizing: border-box; overflow-wrap: break-word; orphans: 4; white-space: pre-wrap; caret-color: rgb(51, 51, 51); font-size: 16px; text-align: justify; text-size-adjust: auto;"></div><h4><span style="font-weight: bold;">2.2.3 生成对抗方式</span></h4><div>在 AAAI18 中，Liu 等人[9]利用 SeqGAN[14] 的思想，利用生成模型 G 来生成摘要，利用判别模型 D 来区分真实摘要与生成摘要。使用强化学习的方法，更新参数。</div><div><span style="font-weight: bold;">2.3</span> <span style="font-weight: bold;">抽取生成式摘要</span></div><div>   抽取式、生成式摘要各有优点，为了结合两者的优点，一些方法也同时使用抽取结合生成的方法来完成摘要任务。</div><div>在生成式摘要中，生成过程往往缺少关键信息的控制和指导，例如 pointer-generator 网络在 copy 的过程中，无法很好地定位关键词语，因此一些方法首先提取关键内容，再进行摘要生成。</div><div>   从直觉上来讲，摘要任务可以大致分为两步，首先选择重要内容，其次进行内容改写。在 EMNLP18 中，Gehrmann 等人[9]基于这种想法，提出了“Bottom Up”方式的摘要， 首先使用“content selector”选择关键信息，其次使用 pointer-generator 网络生成摘要。</div><div>   内容选择部分建模为词语级别序列标注任务，该部分的训练数据通过将摘要对齐到文档，得到词语级别的标签。摘要生成部分使用 pointer-generator 网络，使用内容选择部分计算的概率修改原本 attention 概率，使得解码器仅关注选择的内容。</div><div>   除了上述以序列标注方式来选择关键词的方法以外，在 NAACL18 中，Li 等人[10]使用 TextRank 算法获得关键词，之后使用神经网络获得关键词语的表示，并将该表示结合 pointergenerator 网络生成摘要。</div><div>   上述方法从原文中选择重要的部分用来指导摘要的生成，显式地利用了文本级别的信息，在 EMNLP18 中，Li 等人[11]，使用门控机制，从编码得到的向量表示中选择有用的信息用于之后的摘要生成，属于一种 Soft 方式。在使用层次化 encoder 得到句子级别的向量表示之后，使用门控机制，得到新的句子级别向量，表示从中选择有用信息。其模型 InfoSelection 如图 5所示。</div><div style="text-align: center;"><img src="摘要笔记_files/640 [11]" type="image/jpeg" data-filename="640"/></div><div style="text-align: center;">图 5 InfoSelection 模型</div><div>   在 ACL18 中，Hsu 等人[4]将抽取式模型的输出概率作为句子级别的 attention 权重， 用该权重来调整生成式模型中的词语级别的 attention 权重，如图 6所示，其核心想法为：当词语级别的 attention 权重高时，句子级别的 attention 权重也高。基于此想法提出了 Inconsistency 损失函数，使得模型输出的句子级别的权重和词语级别的权重尽量一致。在最终训练时，首先分别预训练抽取式和生成式模型，之后有两种方式来结合两个模型，Hard 方式：将抽取式模型抽出的关键句直接作为生成式模型的输入；Soft 方式：将抽取式模型的的输出概率用来调整词语级别的权重。</div><div style="text-align: center;"><img src="摘要笔记_files/640 [12]" type="image/jpeg" data-filename="640"/></div><div style="text-align: center;">图6 权重调整过程</div><div><br/></div><div><span style="font-weight: bold;">3. 文本摘要的评价指标</span></div><div>   文本摘要任务属于文本生成的范畴，因此不能用简单的准召率来评测。当前比较常用的评测文本生成的方法大致就是BLEU，ROUGE等。这些方法的缺点在于评测质量还比不上人工，只是从基本语义单元的匹配上去评测候选摘要和标准摘要之间的相似性，缺少语义方面的维度。因此，如何设计一个合适的评测方法，也是目前文本摘要任务的一个研究方向。下面以ROUGE为例简单介绍一下摘要评测的流程。</div><blockquote><div>备注1：摘要的reference(即用于评测的标准摘要）通常是一个集合，即一个候选摘要通常需要跟多个reference综合摘要来比较。</div><div>备注2：还有一种情况是给出的reference直接是文档中的原句，此时相当于对原文中每个句子做一个二分类问题，即一个句子是否是摘要句。这种情况不详细讨论。</div></blockquote><div>   ROUGE的基本原理：统计候选摘要句和标准摘要句重叠的基本语义单元（如n-gram），来评价摘要的质量。根据不同的计算重叠的方式，可以将ROUGE分为以下几类：</div><div style="text-align: center;"><img src="摘要笔记_files/640 [13]" type="image/jpeg" data-filename="640"/></div><div>   ROUGE-N系列，其实就是以n-gram为基本单元，计算两个句子之间的n-gram重合率。每个ROUGE系列的计算结果又可以细分为precision，recall和f-beta分数，下面为ROUGE-N的计算方法：</div><div>   假设候选摘要句为 <img src="摘要笔记_files/640 [14]" type="image/png" data-filename="640"/> ，reference摘要句为 <img src="摘要笔记_files/640 [15]" type="image/png" data-filename="640"/></div><div>   ROUGE-N-precision： <img src="摘要笔记_files/640 [16]" type="image/png" data-filename="640"/></div><div>   ROUGE-N-recall: <img src="摘要笔记_files/640 [17]" type="image/png" data-filename="640"/></div><div>   ROUGE-N-f-beta: <img src="摘要笔记_files/640 [18]" type="image/png" data-filename="640"/></div><div>   ROUGE-L的计算方式与上述类似，但是针对是最长公共子序列的重合率计算。</div><div>   ROGUE-W与ROUGE-L类似，不同的是考虑了连续最长公共子序列应该拥有更大的权重。</div><div>   ROUGE-S，基于的是skip-gram。举个例子来说明skip-gram的含义：</div><blockquote><div>我叫邱震宇</div><div>所有的skip-bigram字符对有：（我叫）（我邱）（我震）（叫邱）（叫震）（叫宇）（邱震）（邱宇）（震宇）</div></blockquote><div>   首先skip-gram必须要按照字符在原始句子中的顺序来组成gram。然后可以根据不同字符数组成词组，但是这些词组不要求字符在原文中连续，可以在中间跳过一些字符。通常会设置一个最大跳跃数m来限制跳跃距离，这是为了防止出现大量无意义的词组。</div><div>   下面介绍使用ROUGE来做摘要评测的通用步骤：</div><blockquote><div>假设当前reference摘要集有N个摘要。</div><div>for i=0;i&lt;N;i++:</div><div>计算剔除第i个reference摘要后，剩余N-1的reference分别与候选句计算rouge值，取最大的那个 rouge_i</div><div>end for</div><div>最后将所有rouge_i计算得到均值。</div></blockquote><div>   最后，关于摘要评测用的工具，github上有很多版本，之前我用的是ROUGE.pl+pyrouge。其中ROUGE.pl是用perl语言写的（不得不说这个脚本调用方式不太方便，对于中文数据还有点bug），而pyrouge则是一个wrapper工具，调用的还是ROUGE.pl，只不过接口更加人性化。当然还可以用一些重写ROUGE功能的脚本代码，但是有些脚本计算得到的结果可能会与实际有偏差，这个就需要多方比对了。</div><div><span style="font-weight: bold;">4. 化繁为简，探究文本摘要真正的奥义</span></div><div><span style="font-weight: bold;">4.1 引子</span></div><div><span style="-en-paragraph:true;">   自从</span><span style="-en-paragraph:true;">Luhn (1958)</span><span style="-en-paragraph:true;">的开创性工作之后，自动文本摘要研究聚焦于经验方法，即构建摘要系统并在标准数据集上尽量取得好的效果，而没有明确重要性的定义</span><span style="-en-paragraph:true;">(Das and Martins, 2010; Nenkova and McKeown, 2012)</span><span style="-en-paragraph:true;">。这种视角需要收集数据集，定义评价标准并迭代的通过要么监督学习要么非监督学习的方法选择表现最好的系统</span><span style="-en-paragraph:true;">(Yao et al., 2017)</span><span style="-en-paragraph:true;">。</span></div><div>   这种纯粹的经验方法可能缺乏指导，因为它们往往不是由更通用的理论框架推动的。尽管这些方法推动了实用解决方案的发展，但是它们只识别了人类模糊直觉的信号：重要性。比如，结构特征如中心性（centrality）和重复次数（repetitions）仍然是最常用的用来衡量重要性的量(Yao et al., 2017; Kedzie et al., 2018)。</div><div>   回顾上述目前文本摘要的现状，主要优化在两方面，一方面是模型的结构，一方面是目标函数的优化，目标函数的优化从原来的摘要句一定是文档中相似句逐渐加入了摘要文本的冗余性与多样性，并也因此改进了各种目标函数， 其中最具代表性的有 submodular function（次膜函数）以及<span style="font-weight: bold;">SummaRuNNer</span></div><div style="text-align: center;"><img src="摘要笔记_files/640 [19]" type="image/jpeg" data-filename="640"/></div><div><span style="-en-paragraph:true;">    但从信息量化的角度来看，摘要的任务也许会更加直观，也更简单。因此我们在一个抽象的理论框架下提出一个简单的信息重要性的定义。这需要信息论的概念，信息论在</span><span style="-en-paragraph:true;">Shannon (1948)</span><span style="-en-paragraph:true;">在通信原理的工作之后引起了广泛的关注。信息论提供了严格地讨论抽象概念信息的方法，这看起来非常适合用来作为摘要的关键理论。然而，信息论聚焦于从一组可能的信息中抽取信息的不确定性（熵），而不考虑信息的语义</span><span style="-en-paragraph:true;">(Shannon, 1948)</span><span style="-en-paragraph:true;">。然而，</span><span style="font-weight: bold;-en-paragraph:true;">摘要是一种基于背景知识的有损的语义压缩过程</span><span style="-en-paragraph:true;">。</span></div><div>   为了将信息论应用到摘要中，我们假设文本是由叫做“语义单元（semantic units）”的概率分布表示的(Bao et al., 2011)。这种视角和常用的文本的分布式嵌入表示是兼容的，这表示我们提出的框架在实际中是可行的。当用于语义信号时，信息论的工具就间接地在语义层级上运作(Carnap and Bar-Hillel, 1953; Zhong, 2017)。</div><div>在下面的段落中，我们用D表示源文档，用S表示候选摘要，他们的分布分别为 PD 和 PSPS。</div><div>4.2</div><div>4.2.1 相关性（Relevance）</div><div>   首先说相关性，目前大部分模型对摘要抽取或生成的目标都可近似为相关性。对于有监督学习训练来说，抽取式摘要的训练数据标注了哪些句子是摘要句。最后任务转化为对每个句子做二分类问题，而生成式摘要的seq2seq模型中，也是与标注的人工摘要进行语义单元上的差异计算。对于无监督学习来说，大部分的方法的建模目标都是相关性。下面按照大致的类别举几个无监督学习的例子：</div><ul><li><div>基于关键词的方法。先使用关键词抽取模型抽取关键词，然后统计包含关键词最多的句子作为候选摘要。关键词抽取应用比较广泛的就是基于tfidf方法。</div></li><li><div>基于主题模型，如LDA，LSA等，分析文档隐含的主题，然后分析句子和主题的相关性。</div></li><li><div>将句子向量化表示，然后对句子进行聚类，隐含的每个聚类代表某个主题，然后从这些主题中挑选摘要句。</div></li><li><div>graph-based方法，以textrank为经典方法，将句子作为节点，句子之间的相似度关系作为边，构建有权图，利用图论中的算法，得到每个句子的权重分数。这种方法，相比较于前面三个不太直观，实质上，它挑选的句子通常是相似性最强的一堆句子中的一个。即textrank认为一个句子如果与它相似的句子数越多，表明这个句子与文档主题内容越相关。</div></li></ul><div>上面几种方法，虽然表面上看建模的目标都不一样，但是实际上都是在朝着相关性的方向走。他们认为文档中覆盖面最大的主题是最能概括原文内容的，因此最终的目标即是找这些主题对应的句子。</div><div>这篇论文则是从一个新的角度来建模相关性：<span style="font-weight: bold;">交叉熵</span>。</div><div>论文认为，通过阅读摘要，应该降低对原文的不确定感，摘要文本应当以最小的信息损失来推断原文文档。而上一小节提到过，摘要和文档都可以当作是一个概率分布，那么做深度学习的同学们应该都比较了解，可以通过交叉熵来建立损失函数，让模型去拟合一个真实的概率分布。这里摘要代表我们的模型，文档代表真实的概率分布。公式如下：<img src="摘要笔记_files/640 [20]" type="image/png" data-filename="640"/></div><div>这里CE指的是交叉熵的函数。注意到这里有个负号。因为交叉熵越小，表示摘要和文档的差异越小，那么相关性应当越强。</div><div style="background-color: rgb(255, 255, 255); padding: 0px; margin: 0.8em 0px; clear: both; min-height: 1em; max-width: 100%; box-sizing: border-box; overflow-wrap: break-word; orphans: 4; white-space: pre-wrap; caret-color: rgb(51, 51, 51); font-size: 16px; text-align: justify; text-size-adjust: auto;"></div><h3>4.2.2 <span style="font-weight: bold;">冗余度</span>（Redundancy）</h3><div>实际生产环境中，使用以相似度为目标建模的方法配以一些人工规则通常能够符合需求。然而，当处理较长的文本时，只以相关性为目标做摘要会遇到一个很明显的问题：<span style="font-weight: bold;">模型会倾向于生成一堆相似度很高的摘要句，而丢失了一些小众主题的信息</span>。这些信息虽然在文档中的比例不高，但是不代表它不重要。尤其是金融领域中的研报或者财报等类型的文本，有些重要信息信息并不会在文本中出现很多次。因此，需要考虑提取尽可能多样化的摘要内容。</div><div>历史上，也有一些学者对摘要的冗余度进行研究的例子。下面分享一些我之前在工作中调研实践过的方法。</div><ul><li><div>MMR，全称<span style="font-weight: bold;">Maximal Marginal Relevance</span>。将相关性和冗余度放在一个目标函数中，使用贪心方法优化目标函数。每次挑选摘要时，除了建模其相关性分数外，还要扣除其与当前已有的摘要集合的冗余度分数，最后挑选综合分数最高的那个加入到摘要集合中。这个方法简单高效，且是无监督的方法，在生产环境中，如果缺少高质量的标注数据，可以使用这个方法。</div></li><li><div>利用submodular函数原理来建模冗余度。关于submodular函数的原理，这里就不展开了，有兴趣的同学可以自行谷歌。它在建模冗余度时，不是惩罚冗余性，而是<span style="font-weight: bold;">奖励多样性。</span>当挑选一个与摘要集合不太相似的句子时会奖励一个较高分数，但是后续如果有与之类似的句子被挑选了，则这个奖励会呈非线性递减，借鉴了经济学中的边际效益思想。之所以奖励多样性，是为了与相关性分数的变化关联一致，维持submodular函数的单调性质。</div></li></ul><div>论文中，对冗余度的建模方法简单到不可思议。它认为，摘要包含的信息量表明了其本身的多样性程度。因此直接使用信息论中的<span style="font-weight: bold;">熵</span>来度量其信息量，即冗余程度。简化后的公式如下：</div><div><img src="摘要笔记_files/640 [21]" type="image/png" data-filename="640"/></div><div>注意到等式右边有一个负号，表示熵越大，文本不确定性越高，信息量也越大，那么其冗余度也越小。</div><h3><span style="font-weight: bold;">4.2.3 信息 （informativeness）</span></h3><div>对于这个单词，我之所以没给中文翻译是因为我还不知道如何确切翻译它，如果翻译成信息量，我觉得还不是很够味。根据论文的叙述，这个概念假设当前有一个背景知识库K，此时需要对文档D进行摘要抽取，那么候选摘要S对于K来说，应当新增尽可能多的信息，才能让读者在阅读摘要后获取最多的新信息。如果摘要句子说的都是用户早就知道的事情，那么阅读摘要没有给用户产生任何价值。</div><div>相关性和冗余度只是在当前处理文档的范围内进行建模，但是人类的语言是有庞大的常识库的。只使用相关性和冗余度有其局限性，因此才引入了informativeness的概念。那么如何度量这个概念呢？论文给出的方法也很简单，informativeness的目标是让S尽可能与K不同，同时K也是由语义单元组成的文本语料集合，因此也可以用 <img src="摘要笔记_files/640 [22]" type="image/png" data-filename="640"/>来表示K的概率分布，那么剩下的工作就很明显了，与相关性类似，使用交叉熵来衡量两个概率分布的差异性。简化后的公式如下：</div><div><img src="摘要笔记_files/640 [23]" type="image/png" data-filename="640"/></div><div>注意等式右边没有负号，表示S和K的差异越大，我从摘要中获取的新的信息越多，则informativeness就应当越大。</div><div><span style="font-weight: bold;">其实，informativeness的内涵与tfidf的思想比较像。</span>tfidf找的是词频较大，但是又不是每篇文章都包含的词。最典型的实例就是会过滤掉停止词，这些词的信息量是很少的。</div><div>有的同学会问了，这个K从哪里来呢？有条件的，可以通过构建大规模的知识库语料，如训练BERT使用的多领域的文本语料；没有条件的，可以直接将需要提取摘要的所有文档集作为K。</div><div><br/></div><div>4.3 目标函数</div><div><span style="font-weight: bold;">               θI(S,D,K)≡−Red(S)+αRel(S,D)+βInf(S,K)</span></div><div><span style="font-weight: bold;-en-paragraph:true;">等式中有一个常数项</span> <span style="font-weight: bold;-en-paragraph:true;">logC</span> <span style="font-weight: bold;-en-paragraph:true;">与</span><span style="font-weight: bold;-en-paragraph:true;">S</span><span style="font-weight: bold;-en-paragraph:true;">无关。最大化</span> <span style="font-weight: bold;-en-paragraph:true;">θI</span> <span style="font-weight: bold;-en-paragraph:true;">等价于最大化相关性和信息度并同时最小化冗余性。</span><span style="-en-paragraph:true;">他们的强度由参数</span> <span style="-en-paragraph:true;">α</span> <span style="-en-paragraph:true;">和</span> <span style="-en-paragraph:true;">β</span> <span style="-en-paragraph:true;">控制。</span></div><div><br/></div><div style="background-color: rgb(255, 255, 255); padding: 0px; margin: 0.8em 0px; clear: both; min-height: 1em; max-width: 100%; box-sizing: border-box; overflow-wrap: break-word; orphans: 4; white-space: pre-wrap; caret-color: rgb(51, 51, 51); font-size: 16px; text-align: justify; text-size-adjust: auto;"></div><h2>4.4 Potential Information</h2><div>   相关性和S和D有关，信息度和S和K有关，我们也可以连接D和K。直觉上来说，只有当K和D不同时，我们才可以从D中抽取大量的新信息。</div><div>类似于信息度，我们可以<span style="font-weight: bold;">定义潜在信息量</span>为：<span style="font-weight: bold;">已知知识</span><span style="font-weight: bold;">K</span><span style="font-weight: bold;">时，观察到</span><span style="font-weight: bold;">D</span><span style="font-weight: bold;">的平均惊讶程度。</span>再一次，这是根据交叉熵计算的：PIK(D)=CE(D,K)：</div><div>PIK(D)=−∑ωiPD(ωi)⋅log(PK(ωi))</div><div>   我们前面说过，一个摘要应该只使用D中的信息，并致力于提供相对于K来说的最大的新信息量。</div><div><span style="-en-paragraph:true;">   PIK(D)</span> <span style="-en-paragraph:true;">可以被理解为潜在信息或者最大化的信息度。也就是在知道知识</span><span style="-en-paragraph:true;">K</span><span style="-en-paragraph:true;">的情况下，一个摘要从</span><span style="-en-paragraph:true;">D</span><span style="-en-paragraph:true;">中抽取的最大的新信息的量。一个摘要</span><span style="-en-paragraph:true;">S</span><span style="-en-paragraph:true;">抽取的信息不可能大于</span><span style="-en-paragraph:true;">PIK(D)</span><span style="-en-paragraph:true;">（如果只使用</span><span style="-en-paragraph:true;">D</span><span style="-en-paragraph:true;">中的信息的话）。</span></div><div><br/></div><div><span style="font-weight: bold;">参考文献</span></div><div>[1] Aishwarya Padmakumar and Akanksha Saran. Unsupervised text summarization using sentence embeddings.</div><div>[2] Ramesh Nallapati, Feifei Zhai, and Bowen Zhou. Summarunner: A recurrent neural network based sequence model for extractive summarization of documents. In Thirty-First AAAI Conference on Artificial Intelligence, 2017.</div><div>[3] Lantao Yu, Weinan Zhang, Jun Wang, and Yong Yu. Seqgan: Sequence generative adversarial nets with policy gradient. In Thirty-First AAAI Conference on Artificial Intelligence, 2017. Xingxing Zhang, Mirella Lapata, Furu Wei, and Ming Zhou. Neural latent extractive document summarization. arXiv preprint arXiv:1808.07187, 2018.</div><div>[4] Aishwarya Jadhav and Vaibhav Rajan. Extractive summarization with swap-net: Sentences and words from alternating pointer networks. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), volume 1, pages 142–151, 2018.</div><div>[5] Romain Paulus, Caiming Xiong, and Richard Socher. A Deep Reinforced Model for Abstractive Summarization. CoRR, 2017.</div><div>[6] Wei Li, Xinyan Xiao, Yajuan Lyu, and Yuanzhuo Wang. Improving neural abstractive document summarization with structural regularization. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 4078–4087, 2018c.</div><div>[7] Ziqiang Cao, Wenjie Li, Sujian Li, and Furu Wei. Retrieve, rerank and rewrite: Soft template based neural summarization. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), volume 1, pages 152–161, 2018.</div><div>[8] Han Guo, Ramakanth Pasunuru, and Mohit Bansal. Soft layer-specific multi-task summarization with entailment and question generation. arXiv preprint arXiv:1805.11004, 2018.</div><div>[9] Sebastian Gehrmann, Yuntian Deng, and Alexander M Rush. Bottom-Up Abstractive Summarization. EMNLP, 2018.</div><div>[10] Chenliang Li, Weiran Xu, Si Li, and Sheng Gao. Guiding generation for abstractive text summarization based on key information guide network. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers), volume 2, pages 55–60, 2018a.</div><div>[11] Wei Li, Xinyan Xiao, Yajuan Lyu, and Yuanzhuo Wang. Improving neural abstractive document summarization with explicit information selection modeling. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 1787–1796, 2018b.</div><div><br/></div><div><br/></div></div><div><br/></div></span>
</div></body></html> 